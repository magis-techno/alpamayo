# ğŸ”ï¸ Alpamayo-R1 æœåŠ¡å™¨éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»å¦‚ä½•åœ¨æœåŠ¡å™¨ä¸Šéƒ¨ç½²å’Œè¿è¡Œ Alpamayo-R1 æ¨¡å‹ï¼Œ**æ”¯æŒä»åä¸ºäº‘OBSä¸‹è½½æ•°æ®å’Œæ¨¡å‹**ï¼Œé€‚ç”¨äºæ— æ³•ç›´æ¥è®¿é—® HuggingFace çš„å†…ç½‘ç¯å¢ƒã€‚

---

## ç›®å½•

1. [ç¯å¢ƒè¦æ±‚](#1-ç¯å¢ƒè¦æ±‚)
2. [å¿«é€Ÿå¼€å§‹](#2-å¿«é€Ÿå¼€å§‹)
3. [ä»OBSä¸‹è½½æ¨¡å‹å’Œæ•°æ®](#3-ä»obsä¸‹è½½æ¨¡å‹å’Œæ•°æ®)
4. [æ‰‹åŠ¨å‡†å¤‡æ¨¡å‹ï¼ˆå¯é€‰ï¼‰](#4-æ‰‹åŠ¨å‡†å¤‡æ¨¡å‹å¯é€‰)
5. [è¿è¡Œæ¨ç†](#5-è¿è¡Œæ¨ç†)
6. [å¸¸è§é—®é¢˜](#6-å¸¸è§é—®é¢˜)

---

## 1. ç¯å¢ƒè¦æ±‚

### ç¡¬ä»¶è¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|---------|---------|
| **GPU** | NVIDIA GPU 24GB+ æ˜¾å­˜ | A100 40GB / H100 |
| **å†…å­˜** | 32GB | 64GB+ |
| **å­˜å‚¨** | 50GBï¼ˆæ¨¡å‹ 22GB + æ•°æ®é›†ï¼‰ | 100GB+ SSD |
| **CUDA** | 12.0+ | 12.4+ |

### è½¯ä»¶è¦æ±‚

- Docker 20.10+ å’Œ `nvidia-container-toolkit`
- é…ç½®å¥½çš„åä¸ºäº‘OBSè®¿é—®å‡­è¯ï¼ˆå¦‚æœéœ€è¦ä»OBSä¸‹è½½ï¼‰

---

## 2. å¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 1: å…‹éš†é¡¹ç›®

```bash
git clone <repository_url>
cd alpamayo
```

### æ­¥éª¤ 2: åˆå§‹åŒ–éƒ¨ç½²ç¯å¢ƒ

```bash
# è¿è¡Œåˆå§‹åŒ–è„šæœ¬
make setup

# æˆ–æ‰‹åŠ¨æ‰§è¡Œ
cd deploy
bash setup.sh
```

åˆå§‹åŒ–è„šæœ¬ä¼šï¼š
- åˆ›å»ºå¿…è¦çš„æ•°æ®ç›®å½•
- æ£€æŸ¥Dockerå’ŒGPUç¯å¢ƒ
- æç¤ºé…ç½®ç¯å¢ƒå˜é‡

### æ­¥éª¤ 3: é…ç½®ç¯å¢ƒå˜é‡

å¤åˆ¶å¹¶ç¼–è¾‘ç¯å¢ƒé…ç½®æ–‡ä»¶ï¼š

```bash
# å¤åˆ¶ç¤ºä¾‹é…ç½®
cp deploy/env.example .env

# ç¼–è¾‘é…ç½®ï¼ˆå¡«å†™OBSå‡­è¯ï¼‰
vim .env
```

**å¿…éœ€é…ç½®ï¼ˆå¦‚æœä½¿ç”¨OBSï¼‰**ï¼š

```bash
# OBSé…ç½®
S3_ENDPOINT=https://obs.cn-southwest-2.myhuaweicloud.com
ACCESS_KEY_ID=your_access_key_here
SECRET_ACCESS_KEY=your_secret_key_here
```

### æ­¥éª¤ 4: æ„å»ºé•œåƒ

```bash
make build
```

### æ­¥éª¤ 5: å¯åŠ¨å®¹å™¨

```bash
make up
```

---

## 3. ä»OBSä¸‹è½½æ¨¡å‹å’Œæ•°æ®

å¦‚æœæ¨¡å‹å’Œæ•°æ®å·²å­˜å‚¨åœ¨åä¸ºäº‘OBSä¸Šï¼Œå¯ä»¥ç›´æ¥ä¸‹è½½ï¼š

### æ–¹å¼ A: ä½¿ç”¨ Makefileï¼ˆæ¨èï¼‰

```bash
# ä¸‹è½½æ¨¡å‹
make download-obs MODEL=obs://your-bucket/models/Alpamayo-R1-10B/

# ä¸‹è½½æ•°æ®é›†
make download-obs DATASET=obs://your-bucket/datasets/PhysicalAI-AV/

# åŒæ—¶ä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†
make download-obs \
    MODEL=obs://your-bucket/models/Alpamayo-R1-10B/ \
    DATASET=obs://your-bucket/datasets/PhysicalAI-AV/
```

### æ–¹å¼ B: è¿›å…¥å®¹å™¨æ‰‹åŠ¨ä¸‹è½½

```bash
# è¿›å…¥å®¹å™¨
make shell

# åœ¨å®¹å™¨å†…è¿è¡Œä¸‹è½½è„šæœ¬
python /app/deploy/download_from_obs.py \
    --model obs://your-bucket/models/Alpamayo-R1-10B/ \
    --model-dir /data/models \
    --dataset obs://your-bucket/datasets/PhysicalAI-AV/ \
    --dataset-dir /data/datasets
```

### æ–¹å¼ C: ä½¿ç”¨ test_obs_upload.py å·¥å…·

é¡¹ç›®æ ¹ç›®å½•æä¾›äº†é€šç”¨çš„OBSå·¥å…·ï¼š

```bash
# ä¸‹è½½æ¨¡å‹ç›®å½•
python test_obs_upload.py \
    --download obs://your-bucket/models/Alpamayo-R1-10B/ \
    --output deploy/data/models/Alpamayo-R1-10B

# ä¸‹è½½æ•°æ®é›†
python test_obs_upload.py \
    --download obs://your-bucket/datasets/PhysicalAI-AV/ \
    --output deploy/data/datasets/PhysicalAI-AV
```

ä¸‹è½½å®Œæˆåï¼Œæ–‡ä»¶ç»“æ„å¦‚ä¸‹ï¼š

```
deploy/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ Alpamayo-R1-10B/       # æ¨¡å‹æƒé‡å’Œé…ç½®
â”‚   â”‚       â”œâ”€â”€ config.json
â”‚   â”‚       â”œâ”€â”€ model.safetensors.index.json
â”‚   â”‚       â”œâ”€â”€ model-00001-of-00009.safetensors
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ datasets/
â”‚       â””â”€â”€ PhysicalAI-AV/          # æ•°æ®é›†ï¼ˆå¯é€‰ï¼‰
â””â”€â”€ ...
```

---

## 4. æ‰‹åŠ¨å‡†å¤‡æ¨¡å‹ï¼ˆå¯é€‰ï¼‰

å¦‚æœæ— æ³•ä½¿ç”¨OBSï¼Œå¯ä»¥æ‰‹åŠ¨å‡†å¤‡æ¨¡å‹ï¼š

### æ–¹æ³• 1: ä» HuggingFace ä¸‹è½½ï¼ˆéœ€è¦å¤–ç½‘ï¼‰

åœ¨æœ‰å¤–ç½‘çš„æœºå™¨ä¸Šï¼š

```bash
# å®‰è£… huggingface_hub
pip install huggingface_hub

# ç™»å½•ï¼ˆéœ€è¦å…ˆç”³è¯·æ¨¡å‹è®¿é—®æƒé™ï¼‰
huggingface-cli login

# ä¸‹è½½æ¨¡å‹
huggingface-cli download nvidia/Alpamayo-R1-10B \
    --local-dir ./Alpamayo-R1-10B

# ä¸‹è½½ Qwen Processor é…ç½®
huggingface-cli download Qwen/Qwen3-VL-2B-Instruct \
    --local-dir ./Qwen3-VL-2B-Instruct \
    --include "*.json" "*.tiktoken" "*.txt"
```

ç„¶åä¼ è¾“åˆ°æœåŠ¡å™¨ï¼š

```bash
# æ‰“åŒ…
tar -czvf alpamayo_models.tar.gz Alpamayo-R1-10B/ Qwen3-VL-2B-Instruct/

# ä¼ è¾“åˆ°æœåŠ¡å™¨
scp alpamayo_models.tar.gz user@server:/path/to/alpamayo/deploy/data/models/

# åœ¨æœåŠ¡å™¨ä¸Šè§£å‹
cd /path/to/alpamayo/deploy/data/models/
tar -xzvf alpamayo_models.tar.gz
```

### æ–¹æ³• 2: ç›´æ¥å¤åˆ¶

å¦‚æœå·²æœ‰æ¨¡å‹æ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶åˆ° `deploy/data/models/` ç›®å½•ã€‚

---

## 5. è¿è¡Œæ¨ç†

### æ–¹å¼ A: ä½¿ç”¨æµ‹è¯•è„šæœ¬

```bash
# è¿›å…¥å®¹å™¨
make shell

# è¿è¡Œæµ‹è¯•æ¨ç†
python /app/src/alpamayo_r1/test_inference.py
```

### æ–¹å¼ B: ä½¿ç”¨ Makefile å‘½ä»¤

```bash
# è¿è¡Œæµ‹è¯•æ¨ç†
make test

# è¿è¡Œæ¨ç†ï¼ˆä½¿ç”¨ SDPA æ³¨æ„åŠ›ï¼Œå¦‚æœ flash-attn ä¸å¯ç”¨ï¼‰
make inference-sdpa
```

### æ–¹å¼ C: ä½¿ç”¨ Jupyter Notebook

```bash
# å¯åŠ¨ Jupyter æœåŠ¡
make jupyter

# æµè§ˆå™¨è®¿é—® http://localhost:8888
# æ‰“å¼€ notebooks/inference.ipynb
```

### æ–¹å¼ D: è‡ªå®šä¹‰æ¨ç†ä»£ç 

```python
import torch
from alpamayo_r1.models.alpamayo_r1 import AlpamayoR1
from alpamayo_r1.load_physical_aiavdataset import load_physical_aiavdataset
from alpamayo_r1 import helper

# åŠ è½½æ¨¡å‹ï¼ˆä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼‰
model_path = "/data/models/Alpamayo-R1-10B"
model = AlpamayoR1.from_pretrained(
    model_path,
    dtype=torch.bfloat16,
    attn_implementation="sdpa"  # æˆ– "flash_attention_2"
).to("cuda")

processor = helper.get_processor(model.tokenizer)

# åŠ è½½æ•°æ®
clip_id = "030c760c-ae38-49aa-9ad8-f5650a545d26"
data = load_physical_aiavdataset(clip_id, maybe_stream=False)

# å‡†å¤‡è¾“å…¥
messages = helper.create_message(data["image_frames"].flatten(0, 1))
inputs = processor.apply_chat_template(
    messages,
    tokenize=True,
    add_generation_prompt=False,
    continue_final_message=True,
    return_dict=True,
    return_tensors="pt",
)

model_inputs = {
    "tokenized_data": inputs,
    "ego_history_xyz": data["ego_history_xyz"],
    "ego_history_rot": data["ego_history_rot"],
}
model_inputs = helper.to_device(model_inputs, "cuda")

# æ¨ç†
torch.cuda.manual_seed_all(42)
with torch.autocast("cuda", dtype=torch.bfloat16):
    pred_xyz, pred_rot, extra = model.sample_trajectories_from_data_with_vlm_rollout(
        data=model_inputs,
        top_p=0.98,
        temperature=0.6,
        num_traj_samples=1,
        max_generation_length=256,
        return_extra=True,
    )

print("Chain-of-Causation:", extra["cot"][0])
print("Predicted trajectory shape:", pred_xyz.shape)
```

---

## 6. å¸¸è§é—®é¢˜

### Q1: Flash Attention å®‰è£…å¤±è´¥

Flash Attention éœ€è¦ç¼–è¯‘ï¼Œå¦‚æœå®‰è£…å¤±è´¥ï¼Œä½¿ç”¨ PyTorch å†…ç½®çš„ SDPAï¼š

```python
model = AlpamayoR1.from_pretrained(
    model_path,
    dtype=torch.bfloat16,
    attn_implementation="sdpa"  # ä½¿ç”¨ PyTorch SDPA
)
```

æˆ–ä½¿ç”¨å‘½ä»¤ï¼š

```bash
make inference-sdpa
```

### Q2: CUDA Out of Memory

- å‡å°‘ `num_traj_samples` å‚æ•°ï¼ˆé»˜è®¤ 1ï¼‰
- æ£€æŸ¥ GPU æ˜¾å­˜ï¼š`make gpu`
- ä½¿ç”¨æ›´å¤§æ˜¾å­˜çš„ GPUï¼ˆæ¨è 40GB+ï¼‰

### Q3: OBSä¸‹è½½å¤±è´¥

ç¡®ä¿ï¼š
1. `.env` æ–‡ä»¶ä¸­çš„OBSå‡­è¯æ­£ç¡®
2. OBSè·¯å¾„æ­£ç¡®ï¼ˆç›®å½•è·¯å¾„å¿…é¡»ä»¥ `/` ç»“å°¾ï¼‰
3. ç½‘ç»œè¿æ¥æ­£å¸¸

æµ‹è¯•OBSè¿æ¥ï¼š

```bash
python test_obs_upload.py --download obs://your-bucket/test-file.txt
```

### Q4: æ¨¡å‹åŠ è½½æ—¶æŠ¥é”™ "Not Found"

ç¡®ä¿ï¼š
1. æ¨¡å‹æ–‡ä»¶å®Œæ•´ä¸‹è½½ï¼ˆæ£€æŸ¥æ‰€æœ‰ `.safetensors` åˆ†ç‰‡ï¼‰
2. è·¯å¾„æ­£ç¡®ï¼ˆå®¹å™¨å†…è·¯å¾„ vs å®¿ä¸»æœºè·¯å¾„ï¼‰
3. ç¦»çº¿æ¨¡å¼ä¸‹è®¾ç½®äº†æ­£ç¡®çš„ç¯å¢ƒå˜é‡

### Q5: æ•°æ®é›†åŠ è½½å¤±è´¥

`physical_ai_av` åŒ…é»˜è®¤ä¼šå°è¯•ä» HuggingFace æµå¼åŠ è½½ã€‚ç¦»çº¿ä½¿ç”¨æ—¶ï¼š

```python
import os
os.environ["HF_HOME"] = "/data/huggingface"
os.environ["HF_HUB_OFFLINE"] = "1"

# ç¦ç”¨æµå¼åŠ è½½
data = load_physical_aiavdataset(clip_id, maybe_stream=False)
```

### Q6: Docker æƒé™é—®é¢˜

å¦‚æœé‡åˆ°æƒé™é”™è¯¯ï¼Œç¡®ä¿ï¼š

```bash
# å°†ç”¨æˆ·æ·»åŠ åˆ° docker ç»„
sudo usermod -aG docker $USER

# é‡æ–°ç™»å½•æˆ–æ‰§è¡Œ
newgrp docker
```

---

## é™„å½•ï¼šMake å‘½ä»¤ä¸€è§ˆ

```bash
make help              # æ˜¾ç¤ºæ‰€æœ‰å‘½ä»¤

# åˆå§‹åŒ–
make setup            # åˆå§‹åŒ–ç¯å¢ƒ
make build            # æ„å»ºé•œåƒ

# å®¹å™¨ç®¡ç†
make up               # å¯åŠ¨å®¹å™¨
make down             # åœæ­¢å®¹å™¨
make shell            # è¿›å…¥å®¹å™¨
make logs             # æŸ¥çœ‹æ—¥å¿—

# æ¨ç†
make test             # è¿è¡Œæµ‹è¯•
make inference        # è¿è¡Œæ¨ç†
make inference-sdpa   # è¿è¡Œæ¨ç†ï¼ˆSDPAæ¨¡å¼ï¼‰

# Jupyter
make jupyter          # å¯åŠ¨ Jupyter
make jupyter-stop     # åœæ­¢ Jupyter

# OBS
make download-obs MODEL=obs://... DATASET=obs://...

# GPU
make gpu              # æŸ¥çœ‹GPUçŠ¶æ€
make gpu-watch        # å®æ—¶ç›‘æ§GPU

# æ¸…ç†
make clean            # æ¸…ç†å®¹å™¨å’Œé•œåƒ
make clean-cache      # æ¸…ç†ç¼“å­˜
```

---

## å‚è€ƒèµ„æ–™

- [Alpamayo-R1 HuggingFace](https://huggingface.co/nvidia/Alpamayo-R1-10B)
- [PhysicalAI-AV Dataset](https://huggingface.co/datasets/nvidia/PhysicalAI-Autonomous-Vehicles)
- [è®ºæ–‡: arXiv:2511.00088](https://arxiv.org/abs/2511.00088)
- [Reference: BUILD_AND_PUSH.md](reference/BUILD_AND_PUSH.md) - OBSå·¥å…·ä½¿ç”¨å‚è€ƒ

---

## è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤ Issue æˆ–å‚è€ƒé¡¹ç›® READMEã€‚
